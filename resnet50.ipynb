{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6382990,"sourceType":"datasetVersion","datasetId":3678616}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\n\n# Load labels from CSV\ntrain_df = pd.read_csv('/kaggle/input/aerial-images-of-palm-trees/Palm-Counting-349images/train_labels.csv')\ntest_df = pd.read_csv('/kaggle/input/aerial-images-of-palm-trees/Palm-Counting-349images/test_labels.csv')\n\n# Create ImageDataGenerators for training and validation sets\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create data generators with custom image loading and labeling functions\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory='/kaggle/input/aerial-images-of-palm-trees/Palm-Counting-349images/train',  # Assuming images are in a 'train' folder\n    x_col='filename',\n    y_col='class',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory='/kaggle/input/aerial-images-of-palm-trees/Palm-Counting-349images/test',  # Assuming images are in a 'test' folder\n    x_col='filename',\n    y_col='class',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)\n\n# Create the base model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add custom top layers\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\npredictions = Dense(2, activation='softmax')(x)  # 2 classes: \"Tree\" and \"Palm\"\n\n# Create the final model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=test_generator\n)\n\n# Evaluate the model on the test set\ntest_loss, test_acc = model.evaluate(test_generator)\nprint('Test accuracy:', test_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:32:48.396103Z","iopub.execute_input":"2024-11-19T15:32:48.396666Z","iopub.status.idle":"2024-11-19T18:46:59.913630Z","shell.execute_reply.started":"2024-11-19T15:32:48.396633Z","shell.execute_reply":"2024-11-19T18:46:59.912744Z"}},"outputs":[{"name":"stdout","text":"Found 10398 validated image filenames belonging to 2 classes.\nFound 2670 validated image filenames belonging to 2 classes.\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1128s\u001b[0m 3s/step - accuracy: 0.8509 - loss: 0.4188 - val_accuracy: 0.8783 - val_loss: 0.3467\nEpoch 2/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1105s\u001b[0m 3s/step - accuracy: 0.8452 - loss: 0.3970 - val_accuracy: 0.8783 - val_loss: 0.3447\nEpoch 3/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1175s\u001b[0m 4s/step - accuracy: 0.8431 - loss: 0.3914 - val_accuracy: 0.8652 - val_loss: 0.3786\nEpoch 4/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1174s\u001b[0m 4s/step - accuracy: 0.8539 - loss: 0.3756 - val_accuracy: 0.8730 - val_loss: 0.3478\nEpoch 5/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1156s\u001b[0m 3s/step - accuracy: 0.8459 - loss: 0.3878 - val_accuracy: 0.8730 - val_loss: 0.3298\nEpoch 6/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1147s\u001b[0m 3s/step - accuracy: 0.8559 - loss: 0.3587 - val_accuracy: 0.8787 - val_loss: 0.3500\nEpoch 7/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 3s/step - accuracy: 0.8493 - loss: 0.3745 - val_accuracy: 0.8730 - val_loss: 0.3279\nEpoch 8/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1135s\u001b[0m 3s/step - accuracy: 0.8568 - loss: 0.3646 - val_accuracy: 0.8730 - val_loss: 0.3265\nEpoch 9/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1120s\u001b[0m 3s/step - accuracy: 0.8521 - loss: 0.3592 - val_accuracy: 0.8730 - val_loss: 0.3268\nEpoch 10/10\n\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1118s\u001b[0m 3s/step - accuracy: 0.8539 - loss: 0.3592 - val_accuracy: 0.8787 - val_loss: 0.3335\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 3s/step - accuracy: 0.8805 - loss: 0.3282\nTest accuracy: 0.8786516785621643\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}